{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace1e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lora.core import LORA, FUSE\n",
    "from load_data import LoadData\n",
    "from mlx_lm import generate, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f44374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "root_folder = \"model_a_1\"\n",
    "\n",
    "data_folder = f\"./{root_folder}/data\"\n",
    "dataset_name = \"n4jiDX/Math-Problems\"\n",
    "n = 1000\n",
    "test_split_ratio = 0.2\n",
    "valid_split_ratio = 0.2\n",
    "\n",
    "model_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "adapter_file = f\"./{root_folder}/adapters.npz\"\n",
    "save_model_path = f\"./{root_folder}/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee83b622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b10cc2fb524a8fac08c4af93777477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': './model_a_1/data/train.jsonl',\n",
       " 'test': './model_a_1/data/test.jsonl',\n",
       " 'valid': './model_a_1/data/valid.jsonl'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Train, Test and Validation Data from the Dataset\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are a math problem solver. Given a math problem, you will provide a step-by-step solution.\n",
    "Use the following format:\n",
    "Problem: <The math problem>\n",
    "Solution: <Step-by-step solution>\n",
    "\"\"\"\n",
    "\n",
    "def create_conversation(input: dict) -> dict:\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message.strip()},\n",
    "            {\"role\": \"user\", \"content\": input[\"Problem\"]},\n",
    "            {\"role\": \"assistant\", \"content\": input[\"Solution\"]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "data_loader = LoadData(folder=data_folder, dataset_name=dataset_name)\n",
    "data_loader.save(function=create_conversation, n=n, test_split_ratio=test_split_ratio, valid_split_ratio=valid_split_ratio, write_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b4e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5e963662814f25807fde0983492762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters 7242.158M\n",
      "Trainable parameters 0.426M\n",
      "Loading datasets\n",
      "Training\n"
     ]
    }
   ],
   "source": [
    "# Fine-Tuning with LoRA\n",
    "\n",
    "lora = LORA(config={\"train\": True, \"batch_size\": 1, \"lora_layers\": 4, \"adapter_file\": adapter_file})\n",
    "lora.invoke(model_path=model_path, data=data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45121ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af69cc0a4fce47e1bec8a54cb73b3d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fuse the LoRA adapters with the base model and save the fine-tuned model\n",
    "\n",
    "fuse = FUSE(config={\"adapter_file\": adapter_file})\n",
    "fuse.invoke(model_path=model_path, save_path=save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To solve this problem, we first need to find the solutions of the equation $|y| = 3(|y| - 2)$.\\n\\nSolving the equation $|y| = 3(|y| - 2)$ means finding the values of $y$ that satisfy the equation. Since $|y|$ is the absolute value of $y$, the equation is satisfied when $y$ is either 3 or $-3$ (the positive and negative solutions).\\n\\nNow, we need to find the product of these solutions:\\n\\n$$\\n\\\\text{Product of solutions} = y_1 \\\\times y_2 \\\\\\\\\\n= 3 \\\\times (-3) \\\\\\\\\\n= -3 \\\\times 3 \\\\\\\\\\n= -9\\n$$\\n\\nSo, the product of the solutions of the equation $|y| = 3(|y| - 2)$ is $\\\\boxed{-9}$.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fine-tuned model and generate a response\n",
    "\n",
    "model, tokenizer = utils.load(save_model_path)\n",
    "generate(model=model, tokenizer=tokenizer, prompt=\"You are a math problem solver. Given a math problem, you will provide a step-by-step solution.\\nUse the following format:\\nProblem: <The math problem>\\nSolution: <Step-by-step solution>\\nUser:Find the product of the solutions of the equation: $|y| = 3(|y| - 2)$.\\nAssistant:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
