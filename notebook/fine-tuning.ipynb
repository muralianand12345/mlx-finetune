{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace1e442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from lora import LORA, FUSE\n",
    "from load_data import LoadData\n",
    "from mlx_lm import generate, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f44374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "root_folder = \"model_a_1\"\n",
    "\n",
    "data_folder = f\"./{root_folder}/data\"\n",
    "dataset_name = \"n4jiDX/Math-Problems\"\n",
    "n = 1000\n",
    "test_split_ratio = 0.2\n",
    "valid_split_ratio = 0.2\n",
    "\n",
    "model_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "adapter_file = f\"./{root_folder}/adapters.npz\"\n",
    "save_model_path = f\"./{root_folder}/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee83b622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a286a48b0e49ac9b8319c90c0bbd7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': './model_a_1/data/train.jsonl',\n",
       " 'test': './model_a_1/data/test.jsonl',\n",
       " 'valid': './model_a_1/data/valid.jsonl'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Train, Test and Validation Data from the Dataset\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are a math problem solver. Given a math problem, you will provide a step-by-step solution.\n",
    "Use the following format:\n",
    "Problem: <The math problem>\n",
    "Solution: <Step-by-step solution>\n",
    "\"\"\"\n",
    "\n",
    "def create_conversation(input: dict) -> dict:\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message.strip()},\n",
    "            {\"role\": \"user\", \"content\": input[\"Problem\"]},\n",
    "            {\"role\": \"assistant\", \"content\": input[\"Solution\"]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "data_loader = LoadData(folder=data_folder, dataset_name=dataset_name)\n",
    "data_loader.save(function=create_conversation, n=n, test_split_ratio=test_split_ratio, valid_split_ratio=valid_split_ratio, write_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b4e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee3ed0a74ad4a00b52f42d2c069247f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters 7242.158M\n",
      "Trainable parameters 0.426M\n",
      "Loading datasets\n",
      "Training\n",
      "Iter 1: Val loss 0.998, Val took 37.477s\n",
      "Iter 10: Train loss 0.960, It/sec 0.471, Tokens/sec 443.263\n",
      "Iter 20: Train loss 0.818, It/sec 0.512, Tokens/sec 389.278\n",
      "Iter 30: Train loss 0.850, It/sec 0.314, Tokens/sec 149.099\n",
      "Iter 40: Train loss 0.823, It/sec 0.226, Tokens/sec 136.215\n",
      "Iter 50: Train loss 0.881, It/sec 0.195, Tokens/sec 88.031\n",
      "Iter 60: Train loss 0.709, It/sec 0.163, Tokens/sec 83.023\n",
      "Iter 70: Train loss 0.802, It/sec 0.218, Tokens/sec 124.225\n",
      "Iter 80: Train loss 0.725, It/sec 0.217, Tokens/sec 154.478\n",
      "[WARNING] Some sequences are longer than 2048 tokens. Consider pre-splitting your data to save memory.\n",
      "Iter 90: Train loss 0.771, It/sec 0.196, Tokens/sec 195.234\n",
      "Iter 100: Train loss 0.741, It/sec 0.287, Tokens/sec 180.082\n",
      "Iter 100: Saved adapter weights to ./model_a_1/adapters.npz.\n",
      "Iter 110: Train loss 0.716, It/sec 0.270, Tokens/sec 131.337\n",
      "Iter 120: Train loss 0.876, It/sec 0.322, Tokens/sec 182.692\n",
      "Iter 130: Train loss 0.814, It/sec 0.389, Tokens/sec 233.204\n",
      "Iter 140: Train loss 0.858, It/sec 0.564, Tokens/sec 269.114\n",
      "Iter 150: Train loss 0.736, It/sec 0.597, Tokens/sec 288.888\n",
      "Iter 160: Train loss 0.806, It/sec 0.613, Tokens/sec 239.729\n",
      "Iter 170: Train loss 0.710, It/sec 0.635, Tokens/sec 282.304\n",
      "Iter 180: Train loss 0.689, It/sec 0.579, Tokens/sec 281.495\n",
      "Iter 190: Train loss 0.772, It/sec 0.668, Tokens/sec 334.713\n",
      "Iter 200: Train loss 0.696, It/sec 0.458, Tokens/sec 281.489\n",
      "Iter 200: Val loss 0.642, Val took 57.535s\n",
      "Iter 200: Saved adapter weights to ./model_a_1/adapters.npz.\n",
      "Iter 210: Train loss 0.696, It/sec 0.456, Tokens/sec 252.813\n",
      "[WARNING] Some sequences are longer than 2048 tokens. Consider pre-splitting your data to save memory.\n",
      "Iter 220: Train loss 0.967, It/sec 0.266, Tokens/sec 258.516\n",
      "Iter 230: Train loss 0.783, It/sec 0.469, Tokens/sec 257.502\n",
      "Iter 240: Train loss 0.824, It/sec 0.392, Tokens/sec 244.989\n",
      "Iter 250: Train loss 0.747, It/sec 0.567, Tokens/sec 287.529\n",
      "Iter 260: Train loss 0.713, It/sec 0.397, Tokens/sec 262.161\n",
      "Iter 270: Train loss 0.774, It/sec 0.382, Tokens/sec 307.682\n",
      "Iter 280: Train loss 0.796, It/sec 0.349, Tokens/sec 268.631\n",
      "Iter 290: Train loss 0.737, It/sec 0.401, Tokens/sec 279.631\n",
      "Iter 300: Train loss 0.719, It/sec 0.403, Tokens/sec 244.160\n",
      "Iter 300: Saved adapter weights to ./model_a_1/adapters.npz.\n",
      "Iter 310: Train loss 0.665, It/sec 0.341, Tokens/sec 248.188\n",
      "Iter 320: Train loss 0.659, It/sec 0.458, Tokens/sec 207.658\n",
      "Iter 330: Train loss 0.605, It/sec 0.402, Tokens/sec 248.587\n",
      "Iter 340: Train loss 0.863, It/sec 0.532, Tokens/sec 294.468\n",
      "Iter 350: Train loss 0.628, It/sec 0.464, Tokens/sec 303.596\n",
      "Iter 360: Train loss 0.792, It/sec 0.544, Tokens/sec 318.340\n",
      "Iter 370: Train loss 0.887, It/sec 0.514, Tokens/sec 278.548\n",
      "Iter 380: Train loss 0.729, It/sec 0.453, Tokens/sec 238.213\n",
      "Iter 390: Train loss 0.728, It/sec 0.461, Tokens/sec 309.324\n",
      "Iter 400: Train loss 0.829, It/sec 0.519, Tokens/sec 290.733\n",
      "Iter 400: Val loss 0.633, Val took 52.134s\n",
      "Iter 400: Saved adapter weights to ./model_a_1/adapters.npz.\n",
      "Iter 410: Train loss 0.687, It/sec 0.307, Tokens/sec 212.830\n",
      "Iter 420: Train loss 0.702, It/sec 0.510, Tokens/sec 281.519\n",
      "Iter 430: Train loss 0.644, It/sec 0.436, Tokens/sec 291.581\n",
      "Iter 440: Train loss 0.585, It/sec 0.464, Tokens/sec 239.126\n",
      "Iter 450: Train loss 0.711, It/sec 0.581, Tokens/sec 275.870\n",
      "Iter 460: Train loss 0.588, It/sec 0.389, Tokens/sec 307.323\n",
      "Iter 470: Train loss 0.629, It/sec 0.373, Tokens/sec 283.809\n",
      "Iter 480: Train loss 0.758, It/sec 0.500, Tokens/sec 305.769\n",
      "Iter 490: Train loss 0.746, It/sec 0.374, Tokens/sec 235.262\n",
      "Iter 500: Train loss 0.645, It/sec 0.455, Tokens/sec 273.069\n",
      "Iter 500: Saved adapter weights to ./model_a_1/adapters.npz.\n",
      "Iter 510: Train loss 0.666, It/sec 0.490, Tokens/sec 311.536\n",
      "Iter 520: Train loss 0.699, It/sec 0.477, Tokens/sec 313.447\n",
      "Iter 530: Train loss 0.713, It/sec 0.399, Tokens/sec 298.590\n",
      "Iter 540: Train loss 0.764, It/sec 0.606, Tokens/sec 316.367\n",
      "Iter 550: Train loss 0.730, It/sec 0.358, Tokens/sec 249.692\n",
      "Iter 560: Train loss 0.744, It/sec 0.271, Tokens/sec 210.732\n",
      "Iter 570: Train loss 0.615, It/sec 0.251, Tokens/sec 147.201\n",
      "Iter 580: Train loss 0.765, It/sec 0.331, Tokens/sec 169.119\n",
      "Iter 590: Train loss 0.699, It/sec 0.294, Tokens/sec 225.907\n",
      "Iter 600: Train loss 0.695, It/sec 0.258, Tokens/sec 148.137\n",
      "Iter 600: Val loss 0.629, Val took 94.473s\n",
      "Iter 600: Saved adapter weights to ./model_a_1/adapters.npz.\n",
      "Iter 610: Train loss 0.719, It/sec 0.266, Tokens/sec 154.663\n",
      "Iter 620: Train loss 0.777, It/sec 0.289, Tokens/sec 182.094\n",
      "[WARNING] Some sequences are longer than 2048 tokens. Consider pre-splitting your data to save memory.\n",
      "Iter 630: Train loss 0.716, It/sec 0.112, Tokens/sec 107.868\n",
      "Iter 640: Train loss 0.884, It/sec 0.297, Tokens/sec 138.214\n",
      "Iter 650: Train loss 0.670, It/sec 0.225, Tokens/sec 183.763\n",
      "Iter 660: Train loss 0.708, It/sec 0.265, Tokens/sec 165.164\n",
      "Iter 670: Train loss 0.798, It/sec 0.287, Tokens/sec 145.014\n",
      "Iter 680: Train loss 0.800, It/sec 0.234, Tokens/sec 156.078\n",
      "Iter 690: Train loss 0.657, It/sec 0.473, Tokens/sec 273.581\n",
      "Iter 700: Train loss 0.599, It/sec 0.430, Tokens/sec 340.707\n",
      "Iter 700: Saved adapter weights to ./model_a_1/adapters.npz.\n",
      "Iter 710: Train loss 0.637, It/sec 0.505, Tokens/sec 340.258\n",
      "Iter 720: Train loss 0.739, It/sec 0.371, Tokens/sec 316.178\n",
      "Iter 730: Train loss 0.660, It/sec 0.307, Tokens/sec 162.036\n",
      "Iter 740: Train loss 0.730, It/sec 0.212, Tokens/sec 134.889\n",
      "Iter 750: Train loss 0.666, It/sec 0.095, Tokens/sec 82.273\n",
      "[WARNING] Some sequences are longer than 2048 tokens. Consider pre-splitting your data to save memory.\n",
      "Iter 760: Train loss 0.825, It/sec 0.104, Tokens/sec 80.809\n",
      "Iter 770: Train loss 0.722, It/sec 0.267, Tokens/sec 166.564\n",
      "Iter 780: Train loss 0.690, It/sec 0.253, Tokens/sec 150.229\n",
      "Iter 790: Train loss 0.857, It/sec 0.276, Tokens/sec 178.852\n",
      "Iter 800: Train loss 0.873, It/sec 0.266, Tokens/sec 151.207\n",
      "Iter 800: Val loss 0.627, Val took 75.330s\n",
      "Iter 800: Saved adapter weights to ./model_a_1/adapters.npz.\n",
      "Iter 810: Train loss 0.728, It/sec 0.256, Tokens/sec 197.737\n",
      "Iter 820: Train loss 0.675, It/sec 0.256, Tokens/sec 182.560\n",
      "Iter 830: Train loss 0.761, It/sec 0.270, Tokens/sec 172.834\n",
      "Iter 840: Train loss 0.565, It/sec 0.256, Tokens/sec 172.093\n",
      "[WARNING] Some sequences are longer than 2048 tokens. Consider pre-splitting your data to save memory.\n",
      "Iter 850: Train loss 0.756, It/sec 0.232, Tokens/sec 149.955\n",
      "Iter 860: Train loss 0.662, It/sec 0.253, Tokens/sec 146.701\n",
      "Iter 870: Train loss 0.714, It/sec 0.224, Tokens/sec 149.443\n",
      "Iter 880: Train loss 0.634, It/sec 0.292, Tokens/sec 135.999\n",
      "Iter 890: Train loss 0.759, It/sec 0.229, Tokens/sec 143.142\n",
      "Iter 900: Train loss 0.605, It/sec 0.280, Tokens/sec 164.615\n",
      "Iter 900: Saved adapter weights to ./model_a_1/adapters.npz.\n",
      "Iter 910: Train loss 0.733, It/sec 0.254, Tokens/sec 162.252\n",
      "Iter 920: Train loss 0.523, It/sec 0.260, Tokens/sec 137.799\n",
      "Iter 930: Train loss 0.674, It/sec 0.282, Tokens/sec 163.895\n",
      "Iter 940: Train loss 0.755, It/sec 0.246, Tokens/sec 125.244\n",
      "Iter 950: Train loss 0.747, It/sec 0.460, Tokens/sec 195.552\n",
      "Iter 960: Train loss 0.598, It/sec 0.306, Tokens/sec 181.874\n",
      "Iter 970: Train loss 0.699, It/sec 0.250, Tokens/sec 171.882\n",
      "Iter 980: Train loss 0.640, It/sec 0.255, Tokens/sec 135.788\n",
      "Iter 990: Train loss 0.703, It/sec 0.266, Tokens/sec 148.884\n",
      "Iter 1000: Train loss 0.628, It/sec 0.253, Tokens/sec 158.352\n",
      "Iter 1000: Val loss 0.625, Val took 93.956s\n",
      "Iter 1000: Saved adapter weights to ./model_a_1/adapters.npz.\n"
     ]
    }
   ],
   "source": [
    "# Fine-Tuning with LoRA\n",
    "\n",
    "lora = LORA(config={\"train\": True, \"batch_size\": 1, \"lora_layers\": 4, \"adapter_file\": adapter_file})\n",
    "lora.invoke(model_path=model_path, data=data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45121ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af69cc0a4fce47e1bec8a54cb73b3d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fuse the LoRA adapters with the base model and save the fine-tuned model\n",
    "\n",
    "fuse = FUSE(config={\"adapter_file\": adapter_file})\n",
    "fuse.invoke(model_path=model_path, save_path=save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To solve this problem, we first need to find the solutions of the equation $|y| = 3(|y| - 2)$.\\n\\nSolving the equation $|y| = 3(|y| - 2)$ means finding the values of $y$ that satisfy the equation. Since $|y|$ is the absolute value of $y$, the equation is satisfied when $y$ is either 3 or $-3$ (the positive and negative solutions).\\n\\nNow, we need to find the product of these solutions:\\n\\n$$\\n\\\\text{Product of solutions} = y_1 \\\\times y_2 \\\\\\\\\\n= 3 \\\\times (-3) \\\\\\\\\\n= -3 \\\\times 3 \\\\\\\\\\n= -9\\n$$\\n\\nSo, the product of the solutions of the equation $|y| = 3(|y| - 2)$ is $\\\\boxed{-9}$.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fine-tuned model and generate a response\n",
    "\n",
    "model, tokenizer = utils.load(save_model_path)\n",
    "generate(model=model, tokenizer=tokenizer, prompt=\"You are a math problem solver. Given a math problem, you will provide a step-by-step solution.\\nUse the following format:\\nProblem: <The math problem>\\nSolution: <Step-by-step solution>\\nUser:Find the product of the solutions of the equation: $|y| = 3(|y| - 2)$.\\nAssistant:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
