{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9807e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def _find_project_root(start: Path = Path.cwd()):\n",
    "\tfor p in [start] + list(start.parents):\n",
    "\t\tif (p / \"pyproject.toml\").exists():\n",
    "\t\t\treturn p\n",
    "\treturn start\n",
    "\n",
    "project_root = _find_project_root()\n",
    "sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e645b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from load_data import LoadData\n",
    "from lora.core import LORA, FUSE\n",
    "from datasets import load_dataset\n",
    "from mlx_lm import generate, utils\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import JSONLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6d7b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(project_root / \".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd01e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "root_folder = \"../../.cache/ragVsFinetuning/model_1\"\n",
    "\n",
    "data_folder = f\"./{root_folder}/data\"\n",
    "dataset_name = \"Kaludi/Customer-Support-Responses\"\n",
    "n = None\n",
    "test_split_ratio = 0.2\n",
    "valid_split_ratio = 0.2\n",
    "\n",
    "model_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "adapter_file = f\"./{root_folder}/adapters.npz\"\n",
    "save_model_path = f\"./{root_folder}/model\"\n",
    "\n",
    "collection_name = \"rag_finetuning_comparison\"\n",
    "rag_data_file=\"../../.cache/ragVsFinetuning/data/data.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9d633",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e16e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c796af406142ff9768b1f0bb890259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data for finetuning\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are a helpful ticket support agent for company XYZ. Provide clear and concise responses to customer queries.\n",
    "\"\"\"\n",
    "\n",
    "def create_conversation(input: dict) -> dict:\n",
    "    if input['query'] is None or input[\"response\"] is None:\n",
    "        pass\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": input[\"query\"]},\n",
    "            {\"role\": \"assistant\", \"content\": input[\"response\"]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "data_loader = LoadData(folder=data_folder, dataset_name=dataset_name)\n",
    "data_loader.save(function=create_conversation, n=n, test_split_ratio=test_split_ratio, valid_split_ratio=valid_split_ratio, write_files=True)\n",
    "\n",
    "# Prepare data for RAG\n",
    "\n",
    "def process_rag_data(dataset_name: str, output_file: str, n: int = None) -> List[dict]:\n",
    "    dataset = load_dataset(dataset_name).select(range(n)).shuffle() if n is not None else load_dataset(dataset_name).shuffle()\n",
    "    \n",
    "    rag_data = []\n",
    "    for i, item in enumerate(tqdm(dataset['train'])):\n",
    "        if item['query'] is None or item['response'] is None:\n",
    "            continue\n",
    "        rag_data.append({\"id\": i, \"query\": item['query'], \"response\": item['response']})\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(rag_data, f, indent=4)\n",
    "\n",
    "process_rag_data(dataset_name=dataset_name, output_file=rag_data_file, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0964bde",
   "metadata": {},
   "source": [
    "## Prepare RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "583df785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afc4c8ac1524472813af8bf9c38bcdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = PGVector(embeddings=embedding_model, collection_name=collection_name, connection=os.getenv(\"PG_CONN_URI\"))\n",
    "\n",
    "def metadata_func(sample: dict, metadata: dict) -> dict:\n",
    "    metadata.update({\n",
    "        \"id\": sample[\"id\"],\n",
    "        \"source\": dataset_name,\n",
    "        \"type\": \"support_ticket\"\n",
    "    })\n",
    "    return metadata\n",
    "\n",
    "loader = JSONLoader(file_path=rag_data_file, jq_schema=\".[]\", text_content=False, metadata_func=metadata_func)\n",
    "docs = loader.load()\n",
    "\n",
    "def batch_add_documents(vector_store: PGVector, documents: List[Document], batch_size: int = 20):\n",
    "    for i in tqdm(range(0, len(documents), batch_size)):\n",
    "        batch = documents[i:i + batch_size]\n",
    "        vector_store.add_documents(batch)\n",
    "\n",
    "batch_add_documents(vector_store, docs, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad1fd63",
   "metadata": {},
   "source": [
    "## Finetune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a8bb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798585857ce546baa6f27d822ec9c560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters 7242.158M\n",
      "Trainable parameters 0.426M\n",
      "Loading datasets\n",
      "Training\n",
      "Iter 1: Val loss 2.731, Val took 3.331s\n",
      "Iter 10: Train loss 2.429, It/sec 3.584, Tokens/sec 265.242\n",
      "Iter 20: Train loss 1.747, It/sec 3.267, Tokens/sec 252.177\n",
      "Iter 30: Train loss 1.127, It/sec 3.282, Tokens/sec 248.801\n",
      "Iter 40: Train loss 0.744, It/sec 3.285, Tokens/sec 237.165\n",
      "Iter 50: Train loss 0.737, It/sec 3.304, Tokens/sec 240.893\n",
      "Iter 60: Train loss 0.666, It/sec 3.287, Tokens/sec 257.057\n",
      "Iter 70: Train loss 0.656, It/sec 3.266, Tokens/sec 252.776\n",
      "Iter 80: Train loss 0.600, It/sec 3.290, Tokens/sec 236.857\n",
      "Iter 90: Train loss 0.578, It/sec 3.192, Tokens/sec 239.732\n",
      "Iter 100: Train loss 0.499, It/sec 3.085, Tokens/sec 223.950\n",
      "Iter 100: Saved adapter weights to ./../../.cache/ragVsFinetuning/model_1/adapters.npz.\n",
      "Iter 110: Train loss 0.524, It/sec 2.999, Tokens/sec 227.655\n",
      "Iter 120: Train loss 0.511, It/sec 2.960, Tokens/sec 222.556\n",
      "Iter 130: Train loss 0.524, It/sec 2.910, Tokens/sec 223.514\n",
      "Iter 140: Train loss 0.540, It/sec 2.995, Tokens/sec 217.471\n",
      "Iter 150: Train loss 0.443, It/sec 2.926, Tokens/sec 216.502\n",
      "Iter 160: Train loss 0.460, It/sec 2.902, Tokens/sec 219.114\n",
      "Iter 170: Train loss 0.434, It/sec 2.907, Tokens/sec 216.540\n",
      "Iter 180: Train loss 0.477, It/sec 2.910, Tokens/sec 224.670\n",
      "Iter 190: Train loss 0.489, It/sec 3.004, Tokens/sec 214.163\n",
      "Iter 200: Train loss 0.438, It/sec 3.031, Tokens/sec 230.344\n",
      "Iter 200: Val loss 0.737, Val took 3.412s\n",
      "Iter 200: Saved adapter weights to ./../../.cache/ragVsFinetuning/model_1/adapters.npz.\n",
      "Iter 210: Train loss 0.377, It/sec 2.922, Tokens/sec 227.305\n",
      "Iter 220: Train loss 0.394, It/sec 2.968, Tokens/sec 220.830\n",
      "Iter 230: Train loss 0.373, It/sec 2.986, Tokens/sec 218.253\n",
      "Iter 240: Train loss 0.388, It/sec 2.995, Tokens/sec 216.528\n",
      "Iter 250: Train loss 0.366, It/sec 3.004, Tokens/sec 226.782\n",
      "Iter 260: Train loss 0.356, It/sec 3.115, Tokens/sec 230.800\n",
      "Iter 270: Train loss 0.372, It/sec 2.983, Tokens/sec 228.517\n",
      "Iter 280: Train loss 0.367, It/sec 3.002, Tokens/sec 223.339\n",
      "Iter 290: Train loss 0.305, It/sec 2.970, Tokens/sec 218.582\n",
      "Iter 300: Train loss 0.321, It/sec 2.773, Tokens/sec 216.600\n",
      "Iter 300: Saved adapter weights to ./../../.cache/ragVsFinetuning/model_1/adapters.npz.\n",
      "Iter 310: Train loss 0.342, It/sec 2.680, Tokens/sec 198.018\n",
      "Iter 320: Train loss 0.343, It/sec 2.851, Tokens/sec 211.861\n",
      "Iter 330: Train loss 0.347, It/sec 2.676, Tokens/sec 198.021\n",
      "Iter 340: Train loss 0.297, It/sec 2.765, Tokens/sec 205.188\n",
      "Iter 350: Train loss 0.291, It/sec 2.329, Tokens/sec 169.319\n",
      "Iter 360: Train loss 0.315, It/sec 2.188, Tokens/sec 168.896\n",
      "Iter 370: Train loss 0.310, It/sec 2.217, Tokens/sec 166.506\n",
      "Iter 380: Train loss 0.283, It/sec 2.101, Tokens/sec 155.695\n",
      "Iter 390: Train loss 0.261, It/sec 1.973, Tokens/sec 146.569\n",
      "Iter 400: Train loss 0.262, It/sec 1.822, Tokens/sec 139.199\n",
      "Iter 400: Val loss 0.819, Val took 6.037s\n",
      "Iter 400: Saved adapter weights to ./../../.cache/ragVsFinetuning/model_1/adapters.npz.\n",
      "Iter 410: Train loss 0.279, It/sec 1.593, Tokens/sec 116.733\n",
      "Iter 420: Train loss 0.298, It/sec 1.424, Tokens/sec 107.634\n",
      "Iter 430: Train loss 0.270, It/sec 1.321, Tokens/sec 100.379\n",
      "Iter 440: Train loss 0.254, It/sec 1.211, Tokens/sec 88.025\n",
      "Iter 450: Train loss 0.271, It/sec 1.146, Tokens/sec 85.734\n",
      "Iter 460: Train loss 0.257, It/sec 1.166, Tokens/sec 87.766\n",
      "Iter 470: Train loss 0.261, It/sec 0.852, Tokens/sec 64.583\n",
      "Iter 480: Train loss 0.232, It/sec 0.333, Tokens/sec 25.537\n",
      "Iter 490: Train loss 0.245, It/sec 0.164, Tokens/sec 12.301\n",
      "Iter 500: Train loss 0.259, It/sec 0.582, Tokens/sec 41.933\n",
      "Iter 500: Saved adapter weights to ./../../.cache/ragVsFinetuning/model_1/adapters.npz.\n",
      "Iter 510: Train loss 0.247, It/sec 0.889, Tokens/sec 66.597\n",
      "Iter 520: Train loss 0.220, It/sec 0.946, Tokens/sec 70.595\n",
      "Iter 530: Train loss 0.221, It/sec 1.066, Tokens/sec 81.456\n",
      "Iter 540: Train loss 0.243, It/sec 1.027, Tokens/sec 76.894\n",
      "Iter 550: Train loss 0.241, It/sec 1.144, Tokens/sec 84.412\n",
      "Iter 560: Train loss 0.235, It/sec 1.176, Tokens/sec 89.389\n",
      "Iter 570: Train loss 0.230, It/sec 1.265, Tokens/sec 93.337\n",
      "Iter 580: Train loss 0.210, It/sec 1.348, Tokens/sec 99.356\n",
      "Iter 590: Train loss 0.224, It/sec 1.367, Tokens/sec 100.331\n",
      "Iter 600: Train loss 0.223, It/sec 1.369, Tokens/sec 105.256\n",
      "Iter 600: Val loss 0.892, Val took 6.200s\n",
      "Iter 600: Saved adapter weights to ./../../.cache/ragVsFinetuning/model_1/adapters.npz.\n",
      "Iter 610: Train loss 0.219, It/sec 1.487, Tokens/sec 111.848\n",
      "Iter 620: Train loss 0.196, It/sec 1.630, Tokens/sec 119.777\n",
      "Iter 630: Train loss 0.202, It/sec 1.672, Tokens/sec 129.068\n",
      "Iter 640: Train loss 0.205, It/sec 1.757, Tokens/sec 127.735\n",
      "Iter 650: Train loss 0.216, It/sec 1.845, Tokens/sec 140.980\n",
      "Iter 660: Train loss 0.216, It/sec 1.926, Tokens/sec 142.297\n",
      "Iter 670: Train loss 0.210, It/sec 2.051, Tokens/sec 155.294\n",
      "Iter 680: Train loss 0.194, It/sec 2.046, Tokens/sec 151.415\n",
      "Iter 690: Train loss 0.198, It/sec 2.077, Tokens/sec 157.849\n",
      "Iter 700: Train loss 0.196, It/sec 2.066, Tokens/sec 153.715\n",
      "Iter 700: Saved adapter weights to ./../../.cache/ragVsFinetuning/model_1/adapters.npz.\n",
      "Iter 710: Train loss 0.197, It/sec 2.108, Tokens/sec 159.178\n",
      "Iter 720: Train loss 0.199, It/sec 2.224, Tokens/sec 159.461\n",
      "Iter 730: Train loss 0.190, It/sec 2.115, Tokens/sec 154.643\n",
      "Iter 740: Train loss 0.196, It/sec 2.128, Tokens/sec 160.473\n",
      "Iter 750: Train loss 0.192, It/sec 2.154, Tokens/sec 164.168\n",
      "Iter 760: Train loss 0.172, It/sec 2.282, Tokens/sec 172.765\n",
      "Iter 770: Train loss 0.184, It/sec 2.440, Tokens/sec 182.986\n",
      "Iter 780: Train loss 0.185, It/sec 2.342, Tokens/sec 179.846\n",
      "Iter 790: Train loss 0.206, It/sec 2.361, Tokens/sec 171.875\n",
      "Iter 800: Train loss 0.181, It/sec 2.431, Tokens/sec 183.313\n",
      "Iter 800: Val loss 0.887, Val took 4.114s\n",
      "Iter 800: Saved adapter weights to ./../../.cache/ragVsFinetuning/model_1/adapters.npz.\n",
      "Iter 810: Train loss 0.180, It/sec 2.443, Tokens/sec 184.469\n",
      "Iter 820: Train loss 0.180, It/sec 2.490, Tokens/sec 186.713\n",
      "Iter 830: Train loss 0.184, It/sec 2.519, Tokens/sec 182.367\n",
      "Iter 840: Train loss 0.185, It/sec 2.468, Tokens/sec 189.513\n",
      "Iter 850: Train loss 0.175, It/sec 2.475, Tokens/sec 187.363\n",
      "Iter 860: Train loss 0.174, It/sec 2.478, Tokens/sec 182.611\n",
      "Iter 870: Train loss 0.175, It/sec 2.464, Tokens/sec 184.583\n",
      "Iter 880: Train loss 0.182, It/sec 2.590, Tokens/sec 188.058\n",
      "Iter 890: Train loss 0.173, It/sec 2.528, Tokens/sec 193.112\n",
      "Iter 900: Train loss 0.171, It/sec 2.442, Tokens/sec 181.216\n",
      "Iter 900: Saved adapter weights to ./../../.cache/ragVsFinetuning/model_1/adapters.npz.\n",
      "Iter 910: Train loss 0.172, It/sec 2.564, Tokens/sec 196.140\n",
      "Iter 920: Train loss 0.170, It/sec 2.547, Tokens/sec 191.299\n",
      "Iter 930: Train loss 0.172, It/sec 2.534, Tokens/sec 187.494\n",
      "Iter 940: Train loss 0.176, It/sec 2.637, Tokens/sec 196.180\n",
      "Iter 950: Train loss 0.163, It/sec 2.577, Tokens/sec 191.176\n",
      "Iter 960: Train loss 0.170, It/sec 2.667, Tokens/sec 194.140\n",
      "Iter 970: Train loss 0.168, It/sec 2.577, Tokens/sec 191.738\n",
      "Iter 980: Train loss 0.167, It/sec 2.587, Tokens/sec 196.888\n",
      "Iter 990: Train loss 0.167, It/sec 2.581, Tokens/sec 199.290\n",
      "Iter 1000: Train loss 0.157, It/sec 2.568, Tokens/sec 194.681\n",
      "Iter 1000: Val loss 0.922, Val took 3.980s\n",
      "Iter 1000: Saved adapter weights to ./../../.cache/ragVsFinetuning/model_1/adapters.npz.\n"
     ]
    }
   ],
   "source": [
    "lora = LORA(config={\"train\": True, \"adapter_file\": adapter_file, \"batch_size\": 1, \"lora_layers\": 4})\n",
    "lora.invoke(model_path=model_path, data=data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aab576c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060e1176aa1045108901b3c2c8ce857a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fuse = FUSE(config={\"adapter_file\": adapter_file})\n",
    "fuse.invoke(model_path=model_path, save_path=save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d68c53",
   "metadata": {},
   "source": [
    "## Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55155002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(query: str) -> Tuple[str, str]:\n",
    "\n",
    "    vectordb = PGVector(embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), collection_name=collection_name, connection=os.environ['PG_CONN_URI'], use_jsonb=True)\n",
    "    rag_simi_result = vectordb.similarity_search(query=query, k=5)\n",
    "    rag_model, rag_tokenizer = utils.load(model_path)\n",
    "    rag_prompt = \"\"\"System: You are a helpful ticket support agent for company XYZ. Provide clear and concise responses to customer queries. RAG Context: {context} User: {query} Answer:\"\"\"\n",
    "    rag_result = generate(model=rag_model, tokenizer=rag_tokenizer, prompt=rag_prompt.format(context=\" \".join([doc.page_content for doc in rag_simi_result]), query=query))\n",
    "    del vectordb, rag_simi_result, rag_model, rag_tokenizer, rag_prompt\n",
    "\n",
    "    finetuned_model, finetuned_tokenizer = utils.load(save_model_path)\n",
    "    finetuned_prompt = \"\"\"System: You are a helpful ticket support agent for company XYZ. Provide clear and concise responses to customer queries. User: {query} Answer:\"\"\"\n",
    "    finetuned_result = generate(model=finetuned_model, tokenizer=finetuned_tokenizer, prompt=query)\n",
    "    del finetuned_model, finetuned_tokenizer\n",
    "\n",
    "    return rag_result, finetuned_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "145e82ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7398a0706734ae5ade6c0f8629cb9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "================RAG==================\n",
      "We apologize for the inconvenience. Could you please provide a clear photo of the damage so we can assess the situation and provide a solution?\n",
      "======================================\n",
      "==============Fine-tuned===============\n",
      "What should I do?\n",
      "\n",
      "Please contact customer service as soon as possible. You will need to provide your order number and a description of the damage.\n",
      "\n",
      "Can I return a product?\n",
      "\n",
      "We accept returns for store credit within 30 days of delivery. To start a return, please contact customer service.\n",
      "\n",
      "What payment methods do you accept?\n",
      "\n",
      "We accept all major credit cards, PayPal, and Apple Pay.\n",
      "\n",
      "How long does shipping take?\n",
      "\n",
      "Shipping times vary depending on your location. Please refer to our shipping policy for more information.\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "query = \"I received a damaged product.\"\n",
    "rag_answer, finetuned_answer = compare(query=query)\n",
    "\n",
    "print(\"======================================\")\n",
    "print(\"================RAG==================\")\n",
    "print(rag_answer)\n",
    "print(\"======================================\")\n",
    "print(\"==============Fine-tuned===============\")\n",
    "print(finetuned_answer)\n",
    "print(\"======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f12113eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678f040175e7422997b0c38bf4321d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "================RAG==================\n",
      "Sure, please provide your order number for us to check the current status.\n",
      "======================================\n",
      "==============Fine-tuned===============\n",
      "\n",
      "\n",
      "You can track your order in a number of ways:\n",
      "\n",
      "- You will receive email updates throughout your order's journey.\n",
      "- You can log into your account and track your order.\n",
      "- You can contact our customer service team for order tracking information.\n",
      "\n",
      "How do I return an item?\n",
      "\n",
      "You can return your item within 30 days of delivery for a full refund.\n",
      "\n",
      "- To start the return process, please contact our customer service team.\n",
      "- You will be provided with a return label.\n",
      "- Once we receive the item, your refund will be processed.\n",
      "\n",
      "For more information, please visit our returns policy page.\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "query = \"I'd like to track my order.\"\n",
    "rag_answer, finetuned_answer = compare(query=query)\n",
    "\n",
    "print(\"======================================\")\n",
    "print(\"================RAG==================\")\n",
    "print(rag_answer)\n",
    "print(\"======================================\")\n",
    "print(\"==============Fine-tuned===============\")\n",
    "print(finetuned_answer)\n",
    "print(\"======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1dc900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
